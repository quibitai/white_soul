/**
 * Hybrid FFmpeg implementation with graceful fallbacks
 * Uses native FFmpeg when available, with smart fallbacks for serverless environments
 */

import ffmpeg from 'fluent-ffmpeg';
import { promises as fs } from 'fs';
import { tmpdir } from 'os';
import { join } from 'path';

// Try to set FFmpeg path, but don't fail if it's missing
let ffmpegAvailable = false;
let ffmpegPath: string | null = null;

/**
 * Initialize FFmpeg with Vercel-optimized fallback strategy
 * Prioritizes reliability and performance for serverless environments
 */
async function initializeFFmpeg(): Promise<boolean> {
  if (ffmpegAvailable) return true;

  const isVercel = process.env.VERCEL === '1';
  const isProduction = process.env.NODE_ENV === 'production';
  
  console.log(`üîß Initializing FFmpeg (Vercel: ${isVercel}, Production: ${isProduction})`);

  // Tier 1: ffmpeg-static (most reliable for serverless)
  try {
    const ffmpegStatic = await import('ffmpeg-static');
    const ffmpegBinaryPath = ffmpegStatic.default;
    
    if (ffmpegBinaryPath && typeof ffmpegBinaryPath === 'string') {
      // Verify the binary exists and is accessible
      await fs.access(ffmpegBinaryPath);
      ffmpeg.setFfmpegPath(ffmpegBinaryPath);
      ffmpegPath = ffmpegBinaryPath;
      ffmpegAvailable = true;
      console.log('‚úÖ FFmpeg initialized with ffmpeg-static:', ffmpegPath);
      return true;
    }
  } catch (error) {
    console.log('‚ö†Ô∏è ffmpeg-static not available:', error instanceof Error ? error.message : 'Unknown error');
  }

  // Tier 2: System FFmpeg (fallback for local development)
  if (!isVercel) {
    try {
      ffmpeg.setFfmpegPath('ffmpeg');
      ffmpegPath = 'ffmpeg';
      ffmpegAvailable = true;
      console.log('‚úÖ FFmpeg initialized with system binary (local dev)');
      return true;
    } catch (error) {
      console.log('‚ö†Ô∏è System FFmpeg not available:', error instanceof Error ? error.message : 'Unknown error');
    }
  }

  console.log('‚ùå No FFmpeg available - audio processing will be disabled');
  return false;
}

/**
 * Stitch audio chunks with crossfade
 * Falls back to simple concatenation if FFmpeg is unavailable
 */
export async function acrossfadeJoin(
  audioBuffers: Buffer[],
  crossfadeMs: number,
  sampleRate: number,
  mono: boolean
): Promise<Buffer> {
  console.log(`üîó Stitching ${audioBuffers.length} audio chunks with ${crossfadeMs}ms crossfade`);
  
  if (audioBuffers.length === 0) {
    throw new Error('No audio buffers provided for stitching');
  }
  
  if (audioBuffers.length === 1) {
    console.log('üìÑ Single chunk, returning as-is');
    return audioBuffers[0];
  }

  const hasFFmpeg = await initializeFFmpeg();
  
  if (!hasFFmpeg) {
    console.log('‚ö†Ô∏è FFmpeg not available, using simple concatenation fallback');
    return Buffer.concat(audioBuffers);
  }

  try {
    console.log('üéµ Using FFmpeg for crossfade stitching...');
    
    // Create temporary directory
    const tempDir = join(tmpdir(), `ffmpeg-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });
    
    try {
      // Write input files
      const inputFiles: string[] = [];
      for (let i = 0; i < audioBuffers.length; i++) {
        const inputPath = join(tempDir, `input${i}.mp3`);
        await fs.writeFile(inputPath, audioBuffers[i]);
        inputFiles.push(inputPath);
      }
      
      const outputPath = join(tempDir, 'output.mp3');
      
      // Build crossfade filter
      const crossfadeSec = crossfadeMs / 1000;
      let filterComplex = '';
      
      if (audioBuffers.length === 2) {
        filterComplex = `[0:a][1:a]acrossfade=d=${crossfadeSec}:c1=tri:c2=tri[out]`;
      } else {
        // Chain multiple crossfades
        let current = '[0:a]';
        for (let i = 1; i < audioBuffers.length; i++) {
          const next = `[${i}:a]`;
          const output = i === audioBuffers.length - 1 ? '[out]' : `[tmp${i}]`;
          filterComplex += `${current}${next}acrossfade=d=${crossfadeSec}:c1=tri:c2=tri${output};`;
          current = `[tmp${i}]`;
        }
        filterComplex = filterComplex.slice(0, -1);
      }
      
      // Execute FFmpeg
      await new Promise<void>((resolve, reject) => {
        const command = ffmpeg();
        
        // Add inputs
        inputFiles.forEach(file => command.input(file));
        
        command
          .complexFilter(filterComplex)
          .outputOptions(['-map', '[out]'])
          .audioFrequency(sampleRate)
          .output(outputPath);
          
        if (mono) {
          command.audioChannels(1);
        }
        
        command
          .on('end', () => resolve())
          .on('error', (err) => reject(err))
          .run();
      });
      
      // Read output
      const outputBuffer = await fs.readFile(outputPath);
      console.log(`‚úÖ FFmpeg crossfade completed, output size: ${outputBuffer.length} bytes`);
      
      return outputBuffer;
      
    } finally {
      // Cleanup temp directory
      try {
        await fs.rm(tempDir, { recursive: true, force: true });
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è Failed to cleanup temp directory:', cleanupError);
      }
    }
    
  } catch (error) {
    console.error('üí• FFmpeg crossfade failed, falling back to concatenation:', error);
    return Buffer.concat(audioBuffers);
  }
}

/**
 * Apply mastering and encoding
 * Falls back to simple format conversion if FFmpeg is unavailable
 */
export async function masterAndEncode(
  inputBuffer: Buffer,
  options: {
    enable: boolean;
    highpassHz: number;
    deesserHz: number;
    deesserAmount: number;
    compressor: {
      ratio: number;
      attackMs: number;
      releaseMs: number;
      gainDb: number;
    };
    loudness: {
      targetLUFS: number;
      truePeakDb: number;
    };
    format: 'wav' | 'mp3' | 'aac';
    bitrateKbps?: number;
  }
): Promise<Buffer> {
  console.log('üéöÔ∏è Starting mastering and encoding...');
  
  const hasFFmpeg = await initializeFFmpeg();
  
  if (!hasFFmpeg) {
    console.log('‚ö†Ô∏è FFmpeg not available, returning input buffer as-is');
    return inputBuffer;
  }

  if (!options.enable) {
    console.log('üîÑ Mastering disabled, applying format conversion only');
  }

  try {
    console.log('üéõÔ∏è Using FFmpeg for mastering...');
    
    // Create temporary directory
    const tempDir = join(tmpdir(), `ffmpeg-master-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });
    
    try {
      // ElevenLabs returns PCM audio, not MP3 - use .pcm extension and specify format
      const inputPath = join(tempDir, 'input.pcm');
      const outputPath = join(tempDir, `output.${options.format}`);
      
      // Write input file
      await fs.writeFile(inputPath, inputBuffer);
      console.log(`üìÅ Input file written: ${inputPath} (${inputBuffer.length} bytes)`);
      console.log(`üîß Input format: PCM 44100Hz (ElevenLabs format)`);
      
      // Build audio filters
      const filters: string[] = [];
      
      if (options.enable) {
        console.log(`üéõÔ∏è Applying audio mastering filters...`);
        
        // High-pass filter to remove low-frequency noise
        if (options.highpassHz > 0) {
          filters.push(`highpass=f=${options.highpassHz}`);
          console.log(`üîä High-pass filter: ${options.highpassHz}Hz`);
        }
        
        // De-esser (reduce harsh sibilant sounds)
        if (options.deesserAmount > 0) {
          const deesserGain = -options.deesserAmount * 10; // Convert 0.5 to -5dB
          filters.push(`equalizer=f=${options.deesserHz}:width_type=h:width=1000:g=${deesserGain}`);
          console.log(`üé§ De-esser: ${options.deesserHz}Hz, ${deesserGain}dB`);
        }
        
        // Dynamic range compression
        const { ratio, attackMs, releaseMs, gainDb } = options.compressor;
        const attackSec = attackMs / 1000;
        const releaseSec = releaseMs / 1000;
        filters.push(`acompressor=ratio=${ratio}:attack=${attackSec}:release=${releaseSec}:makeup=${gainDb}`);
        console.log(`üóúÔ∏è Compressor: ${ratio}:1 ratio, ${attackMs}ms attack, ${releaseMs}ms release, +${gainDb}dB makeup`);
        
        // Loudness normalization (single-pass for simplicity)
        // Note: Single-pass loudnorm is less accurate but works in serverless environments
        filters.push(`loudnorm=I=${options.loudness.targetLUFS}:TP=${options.loudness.truePeakDb}:LRA=7`);
        console.log(`üìä Loudness normalization: ${options.loudness.targetLUFS} LUFS, ${options.loudness.truePeakDb}dB peak`);
      }
      
      // Execute FFmpeg
      await new Promise<void>((resolve, reject) => {
        // Configure input as raw PCM audio from ElevenLabs
        const command = ffmpeg(inputPath)
          .inputFormat('s16le')  // 16-bit signed little-endian PCM
          .inputOptions([
            '-ar', '44100',      // Sample rate: 44.1kHz
            '-ac', '1'           // Channels: 1 (mono)
          ]);
        
        console.log(`üîß FFmpeg command setup:`, {
          inputPath,
          outputPath,
          filtersCount: filters.length,
          filters: filters,
          format: options.format,
          bitrate: options.bitrateKbps
        });
        
        if (filters.length > 0) {
          command.audioFilters(filters);
          console.log(`üéõÔ∏è Applied ${filters.length} audio filters:`, filters);
        }
        
        // Output format
        if (options.format === 'mp3') {
          command.audioCodec('libmp3lame');
          if (options.bitrateKbps) {
            command.audioBitrate(options.bitrateKbps);
          }
          console.log(`üéµ MP3 encoding: codec=libmp3lame, bitrate=${options.bitrateKbps}k`);
        } else if (options.format === 'aac') {
          command.audioCodec('aac');
          if (options.bitrateKbps) {
            command.audioBitrate(options.bitrateKbps);
          }
          console.log(`üéµ AAC encoding: codec=aac, bitrate=${options.bitrateKbps}k`);
        } else {
          command.audioCodec('pcm_s16le');
          console.log(`üéµ WAV encoding: codec=pcm_s16le`);
        }
        
        // Set timeout for Vercel serverless functions (25s max, leave 5s buffer)
        const timeoutMs = process.env.VERCEL === '1' ? 20000 : 30000;
        const timeout = setTimeout(() => {
          command.kill('SIGKILL');
          reject(new Error(`FFmpeg timeout after ${timeoutMs}ms`));
        }, timeoutMs);

        command
          .output(outputPath)
          .on('start', (commandLine) => {
            console.log(`üöÄ FFmpeg command started: ${commandLine}`);
            console.log(`‚è∞ Timeout set to ${timeoutMs}ms`);
          })
          .on('progress', (progress) => {
            // Throttle progress logging to reduce noise
            if (progress.percent && progress.percent % 25 === 0) {
              console.log(`‚è≥ FFmpeg progress: ${progress.percent}% done, time: ${progress.timemark}`);
            }
          })
          .on('end', () => {
            clearTimeout(timeout);
            console.log(`‚úÖ FFmpeg mastering command completed successfully`);
            resolve();
          })
          .on('error', (err) => {
            clearTimeout(timeout);
            console.error(`üí• FFmpeg mastering command failed:`, err);
            reject(err);
          })
          .run();
      });
      
      // Read output and validate
      const outputBuffer = await fs.readFile(outputPath);
      console.log(`‚úÖ FFmpeg mastering completed, output size: ${outputBuffer.length} bytes`);
      
      // Validate output size (should be reasonable for audio)
      if (outputBuffer.length < 1000) {
        throw new Error(`FFmpeg output suspiciously small: ${outputBuffer.length} bytes`);
      }
      
      return outputBuffer;
      
    } finally {
      // Cleanup temp directory
      try {
        await fs.rm(tempDir, { recursive: true, force: true });
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è Failed to cleanup temp directory:', cleanupError);
      }
    }
    
  } catch (error) {
    console.error('üí• FFmpeg mastering failed, returning input buffer:', error);
    return inputBuffer;
  }
}

/**
 * Analyze audio properties
 * Returns reasonable defaults if FFmpeg is unavailable
 */
export async function analyzeAudio(audioBuffer: Buffer): Promise<{
  durationSec: number;
  lufsIntegrated: number;
  truePeakDb: number;
  joinEnergySpikes: Array<{ posMs: number; db: number }>;
}> {
  console.log('üìä Analyzing audio properties...');
  
  const hasFFmpeg = await initializeFFmpeg();
  
  if (!hasFFmpeg) {
    console.log('‚ö†Ô∏è FFmpeg not available, using fallback analysis values');
    return {
      durationSec: Math.round(audioBuffer.length / 44100 / 2), // Rough estimate
      lufsIntegrated: -16,
      truePeakDb: -1.0,
      joinEnergySpikes: []
    };
  }

  try {
    // For now, return reasonable defaults even with FFmpeg
    // Full audio analysis would require more complex FFmpeg commands
    const estimatedDuration = Math.round(audioBuffer.length / 44100 / 2);
    
    console.log(`‚úÖ Audio analysis completed (estimated duration: ${estimatedDuration}s)`);
    return {
      durationSec: estimatedDuration,
      lufsIntegrated: -16,
      truePeakDb: -1.0,
      joinEnergySpikes: []
    };
    
  } catch (error) {
    console.error('üí• Audio analysis failed, using fallback values:', error);
    return {
      durationSec: 30,
      lufsIntegrated: -16,
      truePeakDb: -1.0,
      joinEnergySpikes: []
    };
  }
}
